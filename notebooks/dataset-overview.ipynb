{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from scipy.io.arff import loadarff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"../data/input/dami-base-processed-2000\"\n",
    "file_regex = re.compile('(.*withoutdupl_norm((_\\d\\d)|_v01|_catremoved)?.arff$)')\n",
    "\n",
    "os.listdir(input_dir)\n",
    "\n",
    "target_files = []\n",
    "\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "#     print(root)\n",
    "    for file in files:\n",
    "        target_files += [os.path.join(root, file)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file_name):\n",
    "    data, meta = loadarff(file_name)\n",
    "    data = pd.DataFrame(data, columns=meta.names())\n",
    "    data['label'] = data['outlier'].apply(lambda x: 'outlier' if x == b\"'yes'\" else 'inlier')\n",
    "    data = data.drop(columns=['id', 'outlier'])\n",
    "    # reorder columns\n",
    "    data = data[np.append([x for x in data.columns if x != 'label'], ['label'])]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/input/dami-base-processed-2000/ALOI/ALOI & 2000 & 27 & 61 & 0.03 \\\\\n",
      "../data/input/dami-base-processed-2000/Annthyroid/Annthyroid & 2000 & 21 & 150 & 0.07 \\\\\n",
      "../data/input/dami-base-processed-2000/Arrhythmia/Arrhythmia & 450 & 259 & 206 & 0.46 \\\\\n",
      "../data/input/dami-base-processed-2000/Cardiotocography/Cardiotocography & 2000 & 21 & 441 & 0.22 \\\\\n",
      "../data/input/dami-base-processed-2000/Glass/Glass & 214 & 7 & 9 & 0.04 \\\\\n",
      "../data/input/dami-base-processed-2000/HeartDisease/HeartDisease & 270 & 13 & 120 & 0.44 \\\\\n",
      "../data/input/dami-base-processed-2000/Hepatitis/Hepatitis & 80 & 19 & 13 & 0.16 \\\\\n",
      "../data/input/dami-base-processed-2000/InternetAds/InternetAds & 1966 & 1555 & 368 & 0.19 \\\\\n",
      "../data/input/dami-base-processed-2000/Ionosphere/Ionosphere & 351 & 32 & 126 & 0.36 \\\\\n",
      "../data/input/dami-base-processed-2000/KDDCup99/KDDCup99 & 2000 & 40 & 8 & 0.00 \\\\\n",
      "../data/input/dami-base-processed-2000/Lymphography/Lymphography & 148 & 3 & 6 & 0.04 \\\\\n",
      "../data/input/dami-base-processed-2000/PageBlocks/PageBlocks & 2000 & 10 & 189 & 0.09 \\\\\n",
      "../data/input/dami-base-processed-2000/Parkinson/Parkinson & 195 & 22 & 147 & 0.75 \\\\\n",
      "../data/input/dami-base-processed-2000/PenDigits/PenDigits & 2000 & 16 & 4 & 0.00 \\\\\n",
      "../data/input/dami-base-processed-2000/Pima/Pima & 768 & 8 & 268 & 0.35 \\\\\n",
      "../data/input/dami-base-processed-2000/Shuttle/Shuttle & 1013 & 9 & 13 & 0.01 \\\\\n",
      "../data/input/dami-base-processed-2000/SpamBase/SpamBase & 2000 & 57 & 798 & 0.40 \\\\\n",
      "../data/input/dami-base-processed-2000/Stamps/Stamps & 340 & 9 & 31 & 0.09 \\\\\n",
      "../data/input/dami-base-processed-2000/Waveform/Waveform & 2000 & 21 & 58 & 0.03 \\\\\n",
      "../data/input/dami-base-processed-2000/WBC/WBC & 223 & 9 & 10 & 0.04 \\\\\n",
      "../data/input/dami-base-processed-2000/WDBC/WDBC & 367 & 30 & 10 & 0.03 \\\\\n",
      "../data/input/dami-base-processed-2000/Wilt/Wilt & 2000 & 5 & 107 & 0.05 \\\\\n",
      "../data/input/dami-base-processed-2000/WPBC/WPBC & 198 & 33 & 47 & 0.24 \\\\\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for t in target_files:\n",
    "    data_name = t.split(\"\\\\\")[-1].split(\"_\")[0]\n",
    "    data = pd.read_csv(t, header=None)\n",
    "    data.rename(columns={data.columns[-1]: \"label\" }, inplace = True)\n",
    "    n, m = data.shape\n",
    "    out_ratio = data['label'].value_counts(normalize=True)['outlier']\n",
    "    out_n = data['label'].value_counts(normalize=False)['outlier']\n",
    "    res.append([data_name, n, m, out_n, out_ratio])\n",
    "    print(f'{data_name} & {n} & {m - 1} & {out_n} & {out_ratio:.2f} \\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stats = pd.DataFrame(res, columns = ['data_set_name', 'N', 'M', 'out_n', 'outlier_ratio'])\n",
    "data_stats.to_pickle(\"../data/output/data_stats.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stats.to_latex('tables/data_stats.tex', float_format=\"{:0.2f}\".format)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
